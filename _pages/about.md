---
permalink: /
title:
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I recently completed my Ph.D. in Electrical and Computer Engineering (ECE) at the [University of Toronto](https://www.utoronto.ca/) (UofT), advised by Prof. [Stark C. Draper](https://www.ece.utoronto.ca/people/draper-s/), working at the intersection of distributed systems, machine learning, and data privacy. Before that, I received my MASc. in ECE at UofT, and B.Sc. in Electrical Engineering with a minor in Economics at the [Sharif University of Technology](http://www.en.sharif.edu/).

To expand industry and academic collaborations, I conducted internships at [CISPA Helmholtz Center for Information Security](https://sprintml.com/), Huawei's Accelerated Neural Technology team, and the Chinese University of Hong Kong.
I've also been certified at the [International High-Performance Computing Summer School, Japan (IHPCSS'2019)](https://ss19.ihpcss.org/) and the [North American School of Information Theory, USA (NASIT'2023)](https://nasit.seas.upenn.edu/). 

**I am currently on the 2025 job market. Please contact me if you would like to discuss potential openings or collaborations!**

## Research Interests



I enjoy creating novel solutions for big data and machine learning problems while exploring diverse research topics, transferring ideas across domains, and ensuring practical effectiveness. My research has focused on distributed systems with heterogeneous characteristicsâ€”such as varying computational speeds, privacy constraints, and utility objectives. In such settings, I have worked on **federated learning**, which enables collaborative model training while keeping data local, and **distributed matrix multiplication**, a fundamental operation in ML training and inference. To enhance privacy in federated learning and address stragglers in distributed computation, I have applied ideas from:

* **Optimization** tunes algorithm parameters and ensures training convergence under privacy and utility constraints.

* **Differential privacy** anonymizes data participation by applying controlled perturbation through noise, sampling, and clipping.

* **Randomized, numerically stable, and approximate algorithms** trade off accuracy for faster task recovery using polynomial interpolation.

* **Error-correction codes** add efficient redundant computation through coding and recover results through decoding.

I implemented our differentially private federated learning solutions using Python with PyTorch and Opacus, and evaluated our straggler-resilient methods on Amazon EC2 and Canada's SciNet HPC cluster.


## Selected Publications


<style type="text/css">
  .tg  {border-collapse:collapse;border-spacing:0;}
  .tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px; overflow:hidden;padding:10px 5px;word-break:normal;}
  .tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px; font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
  .tg .tg-oe15{background-color:#ffffff;border-color:#ffffff;text-align:left;vertical-align:top}
  .tg .tg-wk8r{background-color:#ffffff;border-color:#ffffff;text-align:center;vertical-align:top}
</style>

<table class="tg">
  <thead>
    <tr>
      <th class="tg-wk8r">ICLR 2025</th>
      <th class="tg-oe15">Differentially Private Federated Learning with Time-Adaptive Privacy Spending. <br><u>Shahrzad Kiani</u>, Nupur Kulkarni, Adam Dziedzic, Stark Draper, Franziska Boenisch
        <span style="display: block; margin-bottom: -13px;"></span> <br> 
        <a href="https://openreview.net/forum?id=W0nydevOlG&noteId=zEslc0ErHW">
          <img src="https://img.shields.io/badge/PDF-80000f" alt="PDF" style="width: auto; height: 20px;"/>
        </a>
      </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th class="tg-wk8r">JSAIT 2024</th>
      <th class="tg-oe15">Controlled Privacy Leakage Propagation Throughout Overlapping Grouped Learning. <br><u>Shahrzad Kiani</u>, Franziska Boenisch, Stark Draper
        <span style="display: block; margin-bottom: -13px;"></span> <br> 
        <a href="https://ieeexplore.ieee.org/document/10559973">
          <img src="https://img.shields.io/badge/PDF-80000f" alt="PDF" style="width: auto; height: 20px;"/>
        </a>
      </th>
    </tr>
    <tr>
      <th class="tg-wk8r">JSAIT 2022</th>
      <th class="tg-oe15">Successive Approximated Coded Matrix Multiplication. <br><u>Shahrzad Kiani</u>, Stark Draper
        <span style="display: block; margin-bottom: -13px;"></span> <br> 
        <a href="https://ieeexplore.ieee.org/abstract/document/9829717">
          <img src="https://img.shields.io/badge/PDF-80000f" alt="PDF" style="width: auto; height: 20px;"/>
        </a>
      </th>
    </tr>
    <tr>
      <th class="tg-wk8r">TIT 2021</th>
      <th class="tg-oe15">Hierarchical Coded Matrix Multiplication. <br><u>Shahrzad Kiani</u>, Nuwan Ferdinand, Stark Draper
        <span style="display: block; margin-bottom: -13px;"></span> <br> 
        <a href="https://ieeexplore.ieee.org/abstract/document/9252114">
          <img src="https://img.shields.io/badge/PDF-80000f" alt="PDF" style="width: auto; height: 20px;"/>
        </a>
      </th>
    </tr>
  </tbody>
</table>

<br>
  

## News


<table class="tg">
<thead>
  <tr>
    <th class="tg-wk8r"> Mar 2025</th>
    <th class="tg-oe15">I successfully passed my Ph.D. Final Oral Exam and submitted my Ph.D. thesis, which was accepted *as is* (with no required revisions)! Huge thanks to my committee members Prof. Stark Draper, Prof. Mohammad Ali Maddah-Ali, Prof. Azarakhsh Malekian, Prof. Dimitrios Hatzinakos, and Prof. Nicolas Papernot!</th>
  </tr>
  <tr>
    <th class="tg-wk8r">Feb 2025</th>
    <th class="tg-oe15">I was honored to receive the Farid and Diana Najm Graduate Fellowship and Shahid U. H. Qureshi Memorial Scholarship (both awarded to one ECE student per year), as well as the PhD Graduate Award for the second time! Many thanks to the donors for their support and trust in my work!</th>
  </tr>
  <tr>
    <th class="tg-wk8r">Jan 2025</th>
    <th class="tg-oe15">Our paper, "Differentially Private Federated Learning with Time-Adaptive Privacy Spending", has been accepted to ICLR 2025!</th>
  </tr>
  <tr>
    <th class="tg-wk8r">Dec 2024</th>
    <th class="tg-oe15"> I successfully passed my Ph.D. Departmental Oral Exam! Huge thanks to my committee members Prof. Stark Draper, Prof. Nicolas Papernot, and Prof. Dimitrios Hatzinakos. </th>
  </tr>
</thead>
<tbody>
  <!-- Add all other rows here using <td> within <tbody> -->
</tbody>
</table>

<br>

## Personal

Outside of research, I enjoy practicing creativity through cooking and experimenting with new dishes, hiking new trails, and trying to win at backgammon or other strategic games. When I'm not lazy, I spend time gardening. Whenever possible, I travel to explore new cultures.
